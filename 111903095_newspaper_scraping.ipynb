{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "111903095 newspaper scraping.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vzqIaUM2sqZ0"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_url = \"https://www.lokmat.com/\"\n",
        "news = []\n",
        "textfile = open(\"111903095.txt\", \"w+\")"
      ],
      "metadata": {
        "id": "M1uyfS9Hs2LB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_num = 1500\n",
        "while True:\n",
        "  url = \"\".format(page_num)\n",
        "  print(url)\n",
        "  data = requests.get(url)\n",
        "  soup = BeautifulSoup(data.content, 'html.parser')\n",
        "  list_view = soup.find_all(\"section\", {\"class\": \"list-view\"})\n",
        "  for sec in list_view:\n",
        "    try:\n",
        "      figTags = sec.find_all(\"figure\")\n",
        "      for fig in figTags:\n",
        "        link = fig.find_all(\"a\")[0].get(\"href\")\n",
        "        curr_url = start_url + link\n",
        "        article = requests.get(curr_url)\n",
        "        article_data = BeautifulSoup(article.content, 'html.parser')\n",
        "        description = article_data.find(\"h2\", attrs={\"class\": \"article-description\"}).text\n",
        "        content =article_data.find(\"div\", attrs={\"class\": \"article-contentText\"})\n",
        "        news_data =description\n",
        "        for para in content.find_all(\"p\"):\n",
        "          try:\n",
        "            news_data += para.text\n",
        "          except:\n",
        "            continue\n",
        "        #print(news_data)\n",
        "        textfile.write(news_data)\n",
        "        textfile.write(\"\\n\")\n",
        "        news.append(news_data)\n",
        "    except:\n",
        "      continue\n",
        "  if soup.find(\"a\", attrs={\"class\": \"next\"}) is None:\n",
        "      break\n",
        "  page_num += 1\n",
        "  if page_num == 2000:\n",
        "    break\n",
        "textfile.close()\n",
        "print(len(news))"
      ],
      "metadata": {
        "id": "ki5fXOm3s4nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"111903095.txt\")"
      ],
      "metadata": {
        "id": "W8Fh7Jjhs5SD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}